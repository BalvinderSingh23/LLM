https://github.com/mik0w/pallms
https://huggingface.co/datasets/Lakera/gandalf_ignore_instructions
https://wiki.offsecml.com/Welcome+to+the+Offensive+ML+Playbook
https://learnprompting.org/docs/prompt_hacking/injection
https://www.promptingguide.ai/risks/adversarial
https://www.nccgroup.com/research-blog/exploring-prompt-injection-attacks/
https://genai.owasp.org/resource/owasp-top-10-for-llm-applications-2025/
https://lakera-marketing-public.s3.eu-west-1.amazonaws.com/Lakera%2BAI%2B-%2BReal%2BWorld%2BLLM%2BExploits%2B(Jan%2B2024)-min.pdf
https://genai.owasp.org/llm-top-10/
https://llmsecurity.net/
https://www.ibm.com/think/topics/prompt-injection
https://simonwillison.net/
https://lakera-marketing-public.s3.eu-west-1.amazonaws.com/Lakera%2BAI%2B-%2BReal%2BWorld%2BLLM%2BExploits%2B(Jan%2B2024)-min.pdf
https://wiki.offsecml.com/Adversarial+ML/LLM+Attacks/Using+an++API+Endpoint+or+Black+Box/Prompt+Injection/Using+Emojis+and+Encodings
https://github.com/ottosulin/awesome-ai-security
https://github.com/PromptLabs/Prompt-Hacking-Resources
https://github.com/CyberAlbSecOP/Awesome_GPT_Super_Prompting
https://github.com/OWASP/www-project-ai-security-and-privacy-guide/blob/main/content/ai_exchange/content/docs/ai_security_references.md
https://medium.com/bugbountywriteup/exploiting-generative-ai-apps-with-prompt-injection-33b0ff1aa07a
https://systemweakness.com/bypassing-azure-openais-prompt-shield-65ca03be8abb
https://github.com/WibblyOWobbly/WideOpenAI




    Direct Prompt Injection
    Indirect Prompt Injection
    Model Jailbreaking
    System Prompt Leakage
    RAG Poisoning
    Model Extraction (Stealing)
    Token Manipulation
    Overflow via Long Prompts
    Output Poisoning
    Prompt Overflow Attacks
    Hallucination Exploitation
    Prompt Sandboxing Bypass
    System Message Injection
    Triggering Hidden Prompts
    Insecure Data Retrieval

